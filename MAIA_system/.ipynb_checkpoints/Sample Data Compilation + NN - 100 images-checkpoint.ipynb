{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These moduled are required to import to use different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "from keras.utils import np_utils\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Maghav/Desktop/MAIA_work/MAIA_code/MAIA_system'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work/MAIA_code/MAIA_system/train_array/train_array\n"
     ]
    }
   ],
   "source": [
    "cd train_array/train_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command displays all the sample images data we have. Each sample over here has been generated after passing the hdf file into modis_dataset_gen.py as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample10.npz   sample133.npz  sample169.npz  sample208.npz  sample247.npz\r\n",
      "sample107.npz  sample134.npz  sample17.npz   sample209.npz  sample248.npz\r\n",
      "sample108.npz  sample135.npz  sample170.npz  sample210.npz  sample249.npz\r\n",
      "sample109.npz  sample136.npz  sample171.npz  sample211.npz  sample250.npz\r\n",
      "sample11.npz   sample14.npz   sample172.npz  sample212.npz  sample251.npz\r\n",
      "sample110.npz  sample147.npz  sample173.npz  sample213.npz  sample252.npz\r\n",
      "sample111.npz  sample148.npz  sample174.npz  sample214.npz  sample253.npz\r\n",
      "sample112.npz  sample149.npz  sample175.npz  sample215.npz  sample254.npz\r\n",
      "sample113.npz  sample15.npz   sample186.npz  sample226.npz  sample255.npz\r\n",
      "sample114.npz  sample150.npz  sample187.npz  sample227.npz  sample265.npz\r\n",
      "sample115.npz  sample151.npz  sample188.npz  sample228.npz  sample266.npz\r\n",
      "sample116.npz  sample152.npz  sample189.npz  sample229.npz  sample267.npz\r\n",
      "sample12.npz   sample153.npz  sample190.npz  sample230.npz  sample268.npz\r\n",
      "sample127.npz  sample154.npz  sample191.npz  sample231.npz  sample269.npz\r\n",
      "sample128.npz  sample155.npz  sample192.npz  sample232.npz  sample270.npz\r\n",
      "sample129.npz  sample156.npz  sample193.npz  sample233.npz  sample271.npz\r\n",
      "sample13.npz   sample16.npz   sample194.npz  sample234.npz  sample272.npz\r\n",
      "sample130.npz  sample166.npz  sample195.npz  sample235.npz  sample273.npz\r\n",
      "sample131.npz  sample167.npz  sample206.npz  sample245.npz  sample274.npz\r\n",
      "sample132.npz  sample168.npz  sample207.npz  sample246.npz\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data generation\n",
    "\n",
    "This training data is generated by taking all the 4 values (RGB+ 1.38 micron) of each pixel of each image. All these pixel values are added to a the global_data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_data = []\n",
    "file_list = os.listdir()\n",
    "file_sample_num = []\n",
    "for idx in range(len(file_list)):\n",
    "    m = re.search('sample(.+?).npz',file_list[idx])\n",
    "    file_sample_num.append(m.group(1))\n",
    "    curr_file = np.load(file_list[idx])\n",
    "    curr_data = curr_file[\"arr_0\"]\n",
    "    global_data.append(curr_data)\n",
    "shape = np.shape(global_data) \n",
    "training_data = np.reshape(global_data,((shape[0]*shape[1],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15840000, 4)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work/MAIA_code/MAIA_system\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work/MAIA_code/MAIA_system/train_label\n"
     ]
    }
   ],
   "source": [
    "cd train_label/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Label generation\n",
    "\n",
    "These training labels are generated by reading the corresponding cloud mask HDF files and adding them to a global_labels array to create corresponding labels for each pixel. This was done by using the modis_cld_msk.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_labels = []\n",
    "for idx in range(len(file_list)):\n",
    "    curr_file = np.load(\"mask\"+file_sample_num[idx]+\".npz\")\n",
    "    curr_labels = curr_file[\"cloud_mask\"]\n",
    "    global_labels.append(curr_labels)\n",
    "training_labels = np.ravel(global_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was to check for irregularities in training labels as some pixel values were less than 0 which is practically not possible. Due to some irregularities in modis_cld_msk this led to negative pixel values. These were just ignored for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331794\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(training_data)):\n",
    "    if(any(v <= 0 for v in training_data[i])):\n",
    "        training_labels[i] = 4\n",
    "        #print(i)\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over here we try to do binary classification of the data. We try to stay cloud conservative. We try to split the dataset into 90-10 format to do training and testing classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14256000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels = (training_labels > 1).astype(int)\n",
    "#training_labels = np_utils.to_categorical(training_labels, num_classes=None)\n",
    "testing_data = training_data[14256000:]\n",
    "testing_labels = training_labels[14256000:]\n",
    "training_data = training_data[:14256000]\n",
    "training_labels = training_labels[:14256000]\n",
    "len(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block we build a simple neural network of 3 layers with the 'relu' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential() # signifies a sequential coding block\n",
    "model.add(Dense(24,input_dim=4,activation='relu')) # We add fully connected layer of 24 hidden units\n",
    "                                                   # with activation function as the relu\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) # This is the classification layer where we use the sigmoid function for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block compiles the model we created, with :\n",
    "    - The loss as binary_crossentropy ( https://keras.io/losses/ )\n",
    "    - optimizer as adam ( https://keras.io/optimizers/ )\n",
    "    - We use accuracy as metrics to optimise our neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14256000,)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14256000/14256000 [==============================] - 52s - loss: 0.3736 - acc: 0.8374    \n",
      "Epoch 2/10\n",
      "14256000/14256000 [==============================] - 48s - loss: 0.2800 - acc: 0.8771    \n",
      "Epoch 3/10\n",
      "14256000/14256000 [==============================] - 48s - loss: 0.2625 - acc: 0.8881    \n",
      "Epoch 4/10\n",
      "14256000/14256000 [==============================] - 46s - loss: 0.2501 - acc: 0.8947    \n",
      "Epoch 5/10\n",
      "14256000/14256000 [==============================] - 46s - loss: 0.2420 - acc: 0.8984    \n",
      "Epoch 6/10\n",
      "14256000/14256000 [==============================] - 47s - loss: 0.2343 - acc: 0.9026    \n",
      "Epoch 7/10\n",
      "14256000/14256000 [==============================] - 46s - loss: 0.2295 - acc: 0.9049    \n",
      "Epoch 8/10\n",
      "14256000/14256000 [==============================] - 48s - loss: 0.2262 - acc: 0.9064    \n",
      "Epoch 9/10\n",
      "14256000/14256000 [==============================] - 46s - loss: 0.2244 - acc: 0.9069    \n",
      "Epoch 10/10\n",
      "14256000/14256000 [==============================] - 46s - loss: 0.2219 - acc: 0.9075    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1437aada0>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data,training_labels,epochs=10,batch_size=1000) # We train our model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "The following code blocks are used for evaluating out model on the training as well as the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14254112/14256000 [============================>.] - ETA: 0s\n",
      "acc: 90.79%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(training_data,training_labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583456/1584000 [============================>.] - ETA: 0s\n",
      "acc: 83.47%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(testing_data,testing_labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_data = training_data[14256000:]\n",
    "testing_labels = training_labels[14256000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09372474747\n"
     ]
    }
   ],
   "source": [
    "gaussian_naive_bayes(training_data,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(training_data,training_labels):\n",
    "    clf = SVC()\n",
    "    clf.fit(training_data,training_labels)\n",
    "    y_pred = clf.predict(training_data)\n",
    "    print(accuracy_score(training_labels,y_pred)*100)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(training_data,training_labels):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(training_data,training_labels)\n",
    "    y_pred = clf.predict(training_data)\n",
    "    print(accuracy_score(training_labels,y_pred)*100)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd train_array/train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 272\n",
    "curr_data = np.load(\"sample\"+str(idx)+\".npz\")\n",
    "curr_image = curr_data[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd train_label/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_dict = np.load(\"mask\"+str(idx)+\".npz\")\n",
    "image_labels = labels_dict[\"cloud_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(curr_image)):\n",
    "    if(all(v == 0 for v in curr_image[i])):\n",
    "        image_labels[i] = -1\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gaussian_naive_bayes(normalize(curr_image),image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVM(normalize(curr_image),image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work/MAIA_code/MAIA_system\n"
     ]
    }
   ],
   "source": [
    "cd MAIA_system/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Maghav/Desktop/MAIA_work/MAIA_code\n"
     ]
    }
   ],
   "source": [
    "cd MAIA_code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
